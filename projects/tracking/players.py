json_file = '/content/output/inference/inference_coco.json'
image_root = '/content/LhcTGafSgw_all'

from detectron2.data.datasets import load_coco_json
results = load_coco_json(json_file, image_root, dataset_name='players')

from detectron2.data.datasets import register_coco_instances
register_coco_instances('players', {}, json_file, image_root)

import copy
import numpy as np

from detectron2.data import detection_utils as utils
from detectron2.data import transforms as T

class PlayerMapper:
    """
    """

    def __init__(self, cfg):

        self.tfm_gens = utils.build_transform_gen(cfg, False)
        self.img_format = cfg.INPUT.FORMAT

    def __call__(self, dataset_dict):
        """
        Args:
            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.
        Returns:
            dict: a format that builtin models in detectron2 accept
        """
        dataset_dict = copy.deepcopy(dataset_dict)
        image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
        utils.check_image_size(dataset_dict, image)

        image_list = []

        for ann in dataset_dict['annotations']:
          #bbox = BoxMode.convert(ann['bbox'], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)
          bbox = [int(x) for x in ann['bbox']]
          image_crop = image[bbox[1]:(bbox[1]+bbox[3]),bbox[0]:(bbox[0]+bbox[2])]
          image_crop, _ = T.apply_transform_gens(self.tfm_gens, image_crop)
          image_crop = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))

          image_list.append({
              "image": image_crop,
              "height": bbox[3],
              "width": bbox[2],
              "file_name": dataset_dict["file_name"],
          })          

        #dataset_dict["image_list"] = image_list

        new_dict = {"image_list": image_list}

        return new_dict #dataset_dict


import torch

from detectron2.data.common import DatasetFromList, MapDataset
from detectron2.data.dataset_mapper import DatasetMapper
from detectron2.data import samplers

def trivial_batch_collator(batch):
    """
    """

    collated_list = []

    for img in batch:
      collated_list.extend(img['image_list'])

    return collated_list

def build_players_loader(cfg, json_file, image_root):
    """
    """
    dataset_dicts = load_coco_json(json_file, image_root)

    dataset = DatasetFromList(dataset_dicts)
    dataset = MapDataset(dataset, PlayerMapper(cfg))

    sampler = samplers.InferenceSampler(len(dataset))
    # Always use 1 image per worker during inference since this is the
    # standard when reporting inference time in papers.
    batch_sampler = torch.utils.data.sampler.BatchSampler(sampler, 1, drop_last=False)

    data_loader = torch.utils.data.DataLoader(
        dataset,
        num_workers=cfg.DATALOADER.NUM_WORKERS,
        batch_sampler=batch_sampler,
        collate_fn=trivial_batch_collator,
    )
    return data_loader



def parse_args():
    parser = argparse.ArgumentParser()  
    parser.add_argument("--image_dir, type=str)
    parser.add_argument("--json_path, type=str)
    parser.add_argument("--cfg", type=str, default="detectron2://Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv/18131413/model_0039999_e76410.pkl")
    parser.add_argument("--checkpoint", type=str, default="detectron2://Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv/18131413/model_0039999_e76410.pkl")
    parser.add_argument("--nms_threshold, type=float, default=0.5)
    parser.add_argument("--detection_threshold, type=float, default=0.5)
    parser.add_argument("--batch_size, type=int, default=1)

    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    players_loader = build_players_loader(cfg, json_file, image_root)
